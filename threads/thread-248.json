[
    {
        "thread_id": 248,
        "name": "jgarzik",
        "poster_url": "https://bitcointalk.org/index.php?action=profile;u=541",
        "subject": "RFC: ship block chain 1-74000 with release tarballs?",
        "url": "https://bitcointalk.org/index.php?topic=1931.msg24277#msg24277",
        "date": "November 25, 2010, 07:07:51 AM",
        "content": "<div class=\"post\"><br/>It appears that blk0001.dat, where bitcoin stores block chain information, is compatible across Windows, Linux, 32-bit and 64-bit.<br/><br/>Therefore, why not save new users some time by shipping blocks 1-74000 with each release?<br/><br/>Presumably, indexing and verifying a local file would be faster, and use fewer network resources, than downloading all those blocks via P2P.</div>",
        "post_num": 1,
        "is_displayed": true,
        "nested_level": 0
    },
    {
        "thread_id": 248,
        "name": "wumpus",
        "poster_url": "https://bitcointalk.org/index.php?action=profile;u=2252",
        "subject": "Re: RFC: ship block chain 1-74000 with release tarballs?",
        "url": "https://bitcointalk.org/index.php?topic=1931.msg24352#msg24352",
        "date": "November 25, 2010, 01:37:13 PM",
        "content": "<div class=\"post\">Huh, isn't P2P supposed to be faster because you can download from many users at once instead of one source?<br/>(also the reason why some gaming companies use bittorrent to distribute updates)<br/></div>",
        "post_num": 2,
        "is_displayed": true,
        "nested_level": 0
    },
    {
        "thread_id": 248,
        "name": "RHorning",
        "poster_url": "https://bitcointalk.org/index.php?action=profile;u=344",
        "subject": "Re: RFC: ship block chain 1-74000 with release tarballs?",
        "url": "https://bitcointalk.org/index.php?topic=1931.msg24369#msg24369",
        "date": "November 25, 2010, 02:25:37 PM",
        "content": "<div class=\"post\">I have mixed feelings about this.\u00a0 Part of the problem is that there is perceived to be a free good, a network hosting service in the form of Source Forge, which will certainly allow those performing software releases to include considerably more data than is currently the case for Bitcoins.\u00a0 If somehow we were paying for this service as a community in terms of $$$ per MiB, I think it would be a no brainer that this should stay out of the distribution.\u00a0 Unfortunately for this consideration, it is a free good from the perspective of most users.<br/><br/>The other issue is that the network bandwidth between nodes is also a free good.\u00a0 I've suggested in <a href=\"http://bitcointalk.org/index.php?topic=1764.0\">this thread</a> that perhaps the presumption of network bandwidth may also not be considered a free good either.\u00a0 In fact, I believe that it shouldn't be the case, but that is a completely separate issue entirely.<br/><br/>The network bandwidth for downloading the blocks is to me a wash either way, although a new client coming \"on-line\" trying to get the full block chain does suck up a whole bunch of blocks through the Bitcoin network and that impacts anybody who happens to be connected to those nodes.\u00a0 BTW, this is one of the reasons I think it would be incredibly useful to start \"charging\" for bandwidth as a means to discourage this behavior... and of course to earn a few extra Bitcoins on the side.\u00a0 If you can obtain blocks \"free\" from another source, some people might get more creative on how to get that accomplished including downloading a second package on some free file hosting service (perhaps included with the main client distributions) or coming up with a scheme on how to bootstrap new clients that impacts the network in a less obtrusive fashion.<br/><br/>I guess what I'm saying is that while this is a simple solution to a complex problem, it doesn't solve all of the problems including perhaps clients which may store the block data in another format.\u00a0 There also isn't any apparent reason to necessarily encourage other software client distros to include this kind of data or for that matter to put in more than the most minimum number of blocks.\u00a0 Still, raising the issue is useful here and I hope it raises a discussion about the problem.<br/><br/><div class=\"quoteheader\"><a href=\"https://bitcointalk.org/index.php?topic=1931.msg24352#msg24352\">Quote from: witchspace on November 25, 2010, 01:37:13 PM</a></div><div class=\"quote\">Huh, isn't P2P supposed to be faster because you can download from many users at once instead of one source?<br/>(also the reason why some gaming companies use bittorrent to distribute updates)<br/><br/></div><br/>I agree it seems very odd that you would take something which is by its nature distributed through P2P channels and instead put it into a conventional client-server distribution model.\u00a0 Part of why I'm saying that perhaps more thought ought to go into this is perhaps to encourage a bittorrent distribution connection of some sort for a large collection of blocks if somebody has had their client off for awhile or some other kind of experimentation on how to solve this same problem.\u00a0 The problem is that new clients are demanding the whole block chain and really can't get into \"mining\" or confirming new transactions until they have that chain.\u00a0 Let's solve that problem, which is a larger issue.<br/><br/>The other issue is that it seems like a waste of bandwidth to include these blocks in a client when all you are doing is updating the software.\u00a0 I would be just as worried that the block chain might get wiped out by the installation software with this \"older\" version of the chain, forcing older clients to update to the current block all over again, although this is certainly an installation bug.\u00a0 Just because it is a free good doesn't imply there are no other consequences to going this route.</div>",
        "post_num": 3,
        "is_displayed": true,
        "nested_level": 0
    },
    {
        "thread_id": 248,
        "name": "wumpus",
        "poster_url": "https://bitcointalk.org/index.php?action=profile;u=2252",
        "subject": "Re: RFC: ship block chain 1-74000 with release tarballs?",
        "url": "https://bitcointalk.org/index.php?topic=1931.msg24370#msg24370",
        "date": "November 25, 2010, 02:31:34 PM",
        "content": "<div class=\"post\">Indeed, shipping the data with the client is just a kludge.<br/><br/>If the main reason that the bitcoin P2P protocol is so inefficient in transferring large amounts of blocks, that should be fixed. I think that's because of the HDD syncing going on. Maybe this should be held off for the initial download, or the protocol should be made more bittorrent-like for the blocks [0..last-10000], as they are basically set in stone.<br/></div>",
        "post_num": 4,
        "is_displayed": true,
        "nested_level": 0
    },
    {
        "thread_id": 248,
        "name": "satoshi",
        "poster_url": "https://bitcointalk.org/index.php?action=profile;u=3",
        "subject": "Re: RFC: ship block chain 1-74000 with release tarballs?",
        "url": "https://bitcointalk.org/index.php?topic=1931.msg24438#msg24438",
        "date": "November 25, 2010, 05:51:39 PM",
        "content": "<div class=\"post\">It's not the downloading that takes the time, it's verifying and indexing it.<br/><br/>Bandwidthwise, it's more efficient than if you downloaded an archive.\u00a0 Bitcoin only downloads the data in blk0001.dat, which is currently 55MB, and builds blkindex.dat itself, which is 47MB.\u00a0 Building blkindex.dat is what causes all the disk activity.<br/><br/>During the block download, it only flushes the database to disk every 500 blocks.\u00a0 You may see the block count pause at ??499 and ??999.\u00a0 That's when it's flushing.<br/><br/>Doing your own verifying and indexing is the only way to be sure your index data is secure.\u00a0 If you copy blk0001.dat and blkindex.dat from an untrusted source, there's no way to know if you can trust all the contents in them.<br/><br/>Maybe Berkeley DB has some tweaks we can make to enable or increase cache memory.<br/></div>",
        "post_num": 5,
        "is_displayed": true,
        "nested_level": 0
    },
    {
        "thread_id": 248,
        "name": "MrFlibble",
        "poster_url": "https://bitcointalk.org/index.php?action=profile;u=2332",
        "subject": "Re: RFC: ship block chain 1-74000 with release tarballs?",
        "url": "https://bitcointalk.org/index.php?topic=1931.msg24499#msg24499",
        "date": "November 25, 2010, 11:19:55 PM",
        "content": "<div class=\"post\">My first reaction was \"+1 for fast setup\", but most of the 24hr delay I suffered was local disc.\u00a0 Disabling fsync (?) on the database while in catch-up mode would help the most.<br/><br/><div class=\"quoteheader\"><a href=\"https://bitcointalk.org/index.php?topic=1931.msg24352#msg24352\">Quote from: witchspace on November 25, 2010, 01:37:13 PM</a></div><div class=\"quote\">Huh, isn't P2P supposed to be faster because you can download from many users at once instead of one source?<br/>(also the reason why some gaming companies use bittorrent to distribute updates)<br/></div><br/>Good point.\u00a0 But since the sha-256 of the block is wired into the code, it is perfectly reasonable to ship the data too.\u00a0 When the blockchain is over 500meg, I think transfer efficiency will become important.<br/><br/>We have options,<br/><br/><ul style=\"margin-top: 0; margin-bottom: 0;\"><li>ship blockchain from SF until it's not politely within their AUP, then re-evaluate.\u00a0 I couldn't find a file size limit, even for the project website service (only a quick surf of their docs).</li><li>ship 'small' binaries from SF, and 'large' releases with data via BitTorrent</li><li>ship 'small' release, including the .torrent for the blockchain and a fetcher script. This looks for one of three popular command line BitTorrent clients for the platform and uses that to fetch the chain, or whinge if it can't.</li></ul><br/><a href=\"http://sourceforge.net/apps/trac/sourceforge/wiki/Developer%20web\">http://sourceforge.net/apps/trac/sourceforge/wiki/Developer%20web</a> says<br/><div class=\"quoteheader\">Quote</div><div class=\"quote\">Note: All file releases should be a single file. Multiple files for the same release should be archived together (tar, deb, zip, etc.). We recommend using rsync for all uploads over 20 megabytes in size, as rsync allows for resuming canceled or interrupted transfers. <br/></div><br/>Hmm, shipping the blockchain for each binary arch would be perverse.<br/><br/><br/>Then, who provides the tracker &amp; seed for the data?\u00a0 Someone with incentive or community spirit?\u00a0 Well, this forum+wiki seem to live on <a href=\"http://www.slicehost.com/\">http://www.slicehost.com/</a> =&gt; min $20/month.\u00a0 It could probably share without hurting the website, and (I think) the seed could be severely throttled to make other BT seeds pull more weight.<br/></div>",
        "post_num": 6,
        "is_displayed": true,
        "nested_level": 0
    },
    {
        "thread_id": 248,
        "name": "jgarzik",
        "poster_url": "https://bitcointalk.org/index.php?action=profile;u=541",
        "subject": "Re: RFC: ship block chain 1-74000 with release tarballs?",
        "url": "https://bitcointalk.org/index.php?topic=1931.msg24518#msg24518",
        "date": "November 26, 2010, 01:47:43 AM",
        "content": "<div class=\"post\"><div class=\"quoteheader\"><a href=\"https://bitcointalk.org/index.php?topic=1931.msg24438#msg24438\">Quote from: satoshi on November 25, 2010, 05:51:39 PM</a></div><div class=\"quote\">It's not the downloading that takes the time, it's verifying and indexing it.<br/></div><br/>This is not true of many novice users, who say things like \"well it took several hours to catch all the 90 000 blocks but finally it arrived\" (quoted from one new user, on IRC, today).<br/><br/><div class=\"quoteheader\">Quote</div><div class=\"quote\">Bandwidthwise, it's more efficient than if you downloaded an archive.<br/></div><br/>Agreed. \u00a0Compressed in an archive, blk0001.dat is around 36MB.<br/><br/><div class=\"quoteheader\">Quote</div><div class=\"quote\">Bitcoin only downloads the data in blk0001.dat, which is currently 55MB, and builds blkindex.dat itself, which is 47MB. \u00a0Building blkindex.dat is what causes all the disk activity.<br/><br/>During the block download, it only flushes the database to disk every 500 blocks. \u00a0You may see the block count pause at ??499 and ??999. \u00a0That's when it's flushing.<br/></div><br/>It remains the download, not the verification, that has the highest <i>variability of experience</i>, where first time users see a delay of 30 minutes to <b>several hours</b> before the software is actually usable. \u00a0Some P2P nodes may be extremely slow (I see high variability in latency and throughput for old blocks, and blocks larger than 512 bytes). \u00a0End user bandwidth may be low, spotty or expensive. \u00a0Firewalls are often a problem.<br/><br/>I'm betting that the above complaint from a new user was due to a Microsoft firewall; but the point stands:\u00a0 large variance of network configuration and capability implies the P2P download impact <i>may be</i> far, far greater than impact of on-disk verification of 90,000 blocks.<br/><br/><div class=\"quoteheader\">Quote</div><div class=\"quote\">Doing your own verifying and indexing is the only way to be sure your index data is secure. \u00a0If you copy blk0001.dat and blkindex.dat from an untrusted source, there's no way to know if you can trust all the contents in them.<br/></div><br/>Who said untrusted? \u00a0The proposal is that you distribute blk0001.dat (and only blk0001.dat) in the bitcoin.org official client downloads. \u00a0And of course the client will spend some time verifying blk0001.dat upon first use. \u00a0This is unavoidable, and nobody has proposed changing or eliminating verification.<br/><br/>Just shipping blk0001.dat with official bitcoin would eliminate several headaches that new bitcoin users continue to experience.<br/></div>",
        "post_num": 7,
        "is_displayed": true,
        "nested_level": 0
    },
    {
        "thread_id": 248,
        "name": "jgarzik",
        "poster_url": "https://bitcointalk.org/index.php?action=profile;u=541",
        "subject": "Re: RFC: ship block chain 1-74000 with release tarballs?",
        "url": "https://bitcointalk.org/index.php?topic=1931.msg24522#msg24522",
        "date": "November 26, 2010, 02:07:43 AM",
        "content": "<div class=\"post\"><div class=\"quoteheader\"><a href=\"https://bitcointalk.org/index.php?topic=1931.msg24438#msg24438\">Quote from: satoshi on November 25, 2010, 05:51:39 PM</a></div><div class=\"quote\">Maybe Berkeley DB has some tweaks we can make to enable or increase cache memory.<br/></div><br/>Which of the <a href=\"http://en.wikipedia.org/wiki/ACID\">ACID</a> properties do you need, while downloading?<br/><br/>Adding BDB records is simply appending to a log file, until you <a href=\"http://www.mathematik.uni-ulm.de/help/BerkeleyDB/ref/transapp/checkpoint.html\">issue a checkpoint</a>. \u00a0The checkpoint then updates the main database file.<br/><br/>Under a normal BDB transaction, you are guaranteed that each log record will be sync'd to disk platter, before the transaction commit succeeds. This is very strict, but required for full ACID. Enabling <a href=\"http://www.mathematik.uni-ulm.de/help/BerkeleyDB/api_c/env_set_flags.html\">DB_TXN_NOSYNC</a> still gives you a lot:<br/><br/>\u00a0\u00a0 \u00a0 \"database integrity will be maintained, but if the application or system fails, it is possible<br/>\u00a0\u00a0 \u00a0 \u00a0some number of the most recently committed transactions may be undone during recovery\"<br/><br/>bitcoin can obviously recover if recent transactions are undone, so, it seems useful for this flag to be set for 100% of the initial block download.<br/><br/>That leaves checkpointing, which is a balance between amount of work performed at checkpoint time -- number of records that must be copied from log to database file -- and wall clock time. \u00a0Just gotta try some values and see what \"feels\" right -- maybe checkpoint every 10,000 blocks?</div>",
        "post_num": 8,
        "is_displayed": true,
        "nested_level": 0
    },
    {
        "thread_id": 248,
        "name": "satoshi",
        "poster_url": "https://bitcointalk.org/index.php?action=profile;u=3",
        "subject": "Re: RFC: ship block chain 1-74000 with release tarballs?",
        "url": "https://bitcointalk.org/index.php?topic=1931.msg24662#msg24662",
        "date": "November 26, 2010, 05:32:01 PM",
        "content": "<div class=\"post\">I tested it on a slow 7 year old drive, where bandwidth and CPU were clearly not the bottleneck. \u00a0Initial download took 1 hour 20 minutes.<br/><br/>If it's taking a lot longer than that, certainly 24 hours, then it must be downloading from a very slow node, or your connection is much slower than around 15KB per sec (120kbps), or something else is wrong. \u00a0It would be nice to know what appears to be the bottleneck when that happens.<br/><br/>Every 10 minutes or so when the latest block is sent, it should have the chance to change to a faster node. \u00a0When the latest block is broadcast, it requests the next 500 blocks from other nodes, and continues the download from the one that sends it fastest. \u00a0At least, that's how it should work.<br/><br/><div class=\"quoteheader\"><a href=\"https://bitcointalk.org/index.php?topic=1931.msg24522#msg24522\">Quote from: jgarzik on November 26, 2010, 02:07:43 AM</a></div><div class=\"quote\"><div class=\"quoteheader\"><a href=\"https://bitcointalk.org/index.php?topic=1931.msg24438#msg24438\">Quote from: satoshi on November 25, 2010, 05:51:39 PM</a></div><div class=\"quote\">Maybe Berkeley DB has some tweaks we can make to enable or increase cache memory.<br/></div>Which of the <a href=\"http://en.wikipedia.org/wiki/ACID\">ACID</a> properties do you need, while downloading?<br/></div>It may only need more read caching. \u00a0It has to read randomly all over blk0001.dat and blkindex.dat to index. \u00a0It can't assume the file is smaller than memory, although it currently still is. \u00a0Caching would be effective, since most dependencies are recent.<br/><br/>Someone should experiment with different Berkeley DB settings and see if there's something that makes the download substantially faster. \u00a0If something substantial is discovered, then we can work out the particulars.<br/><br/><div class=\"quoteheader\">Quote</div><div class=\"quote\">Adding BDB records is simply appending to a log file, until you issue a checkpoint. \u00a0The checkpoint then updates the main database file.</div>We checkpoint every 500 blocks.</div>",
        "post_num": 9,
        "is_displayed": true,
        "nested_level": 0
    },
    {
        "thread_id": 248,
        "name": "RHorning",
        "poster_url": "https://bitcointalk.org/index.php?action=profile;u=344",
        "subject": "Re: RFC: ship block chain 1-74000 with release tarballs?",
        "url": "https://bitcointalk.org/index.php?topic=1931.msg24664#msg24664",
        "date": "November 26, 2010, 05:42:17 PM",
        "content": "<div class=\"post\"><div class=\"quoteheader\"><a href=\"https://bitcointalk.org/index.php?topic=1931.msg24518#msg24518\">Quote from: jgarzik on November 26, 2010, 01:47:43 AM</a></div><div class=\"quote\">Who said untrusted? \u00a0The proposal is that you distribute blk0001.dat (and only blk0001.dat) in the bitcoin.org official client downloads. \u00a0And of course the client will spend some time verifying blk0001.dat upon first use. \u00a0This is unavoidable, and nobody has proposed changing or eliminating verification.<br/><br/>Just shipping blk0001.dat with official bitcoin would eliminate several headaches that new bitcoin users continue to experience.<br/><br/></div><br/>My personal suggestion is to have the block data as a separate download, but strongly recommended.\u00a0 If you want to simplify the installation for Windows users and otherwise clueless computer users that can't take a block file of this nature and put it into the correct directory, perhaps setting up a formal installation file to put it where it needs to go would be more \"user friendly\", but all it really has to contain is just the block data.<br/><br/>The purpose of this is mainly so those who are updating to a new version can do so without having to also keep downloading the same block data, which by definition is going to grow over time.</div>",
        "post_num": 10,
        "is_displayed": true,
        "nested_level": 0
    },
    {
        "thread_id": 248,
        "name": "zipslack",
        "poster_url": "https://bitcointalk.org/index.php?action=profile;u=2084",
        "subject": "Re: RFC: ship block chain 1-74000 with release tarballs?",
        "url": "https://bitcointalk.org/index.php?topic=1931.msg24670#msg24670",
        "date": "November 26, 2010, 06:08:40 PM",
        "content": "<div class=\"post\"><div class=\"quoteheader\"><a href=\"https://bitcointalk.org/index.php?topic=1931.msg24664#msg24664\">Quote from: RHorning on November 26, 2010, 05:42:17 PM</a></div><div class=\"quote\">The purpose of this is mainly so those who are updating to a new version can do so without having to also keep downloading the same block data, which by definition is going to grow over time.<br/></div><br/>I'm not sure how it is for you, but when I upgrade Bitcoin I don't have to re-download any blocks. It just picks up right where it left off before the upgrade.</div>",
        "post_num": 11,
        "is_displayed": true,
        "nested_level": 0
    },
    {
        "thread_id": 248,
        "name": "RHorning",
        "poster_url": "https://bitcointalk.org/index.php?action=profile;u=344",
        "subject": "Re: RFC: ship block chain 1-74000 with release tarballs?",
        "url": "https://bitcointalk.org/index.php?topic=1931.msg24679#msg24679",
        "date": "November 26, 2010, 07:17:25 PM",
        "content": "<div class=\"post\"><div class=\"quoteheader\"><a href=\"https://bitcointalk.org/index.php?topic=1931.msg24670#msg24670\">Quote from: zipslack on November 26, 2010, 06:08:40 PM</a></div><div class=\"quote\"><div class=\"quoteheader\"><a href=\"https://bitcointalk.org/index.php?topic=1931.msg24664#msg24664\">Quote from: RHorning on November 26, 2010, 05:42:17 PM</a></div><div class=\"quote\">The purpose of this is mainly so those who are updating to a new version can do so without having to also keep downloading the same block data, which by definition is going to grow over time.<br/></div><br/>I'm not sure how it is for you, but when I upgrade Bitcoin I don't have to re-download any blocks. It just picks up right where it left off before the upgrade.<br/></div><br/>That is the point.\u00a0 If the blocks are included in the update it would also by definition include blocks you already have obtained via the network.\u00a0 This is why I'm suggesting that it ought to be a separate but strongly recommended download for new users instead of something combined in the normal distros.</div>",
        "post_num": 12,
        "is_displayed": true,
        "nested_level": 0
    },
    {
        "thread_id": 248,
        "name": "jgarzik",
        "poster_url": "https://bitcointalk.org/index.php?action=profile;u=541",
        "subject": "Re: RFC: ship block chain 1-74000 with release tarballs?",
        "url": "https://bitcointalk.org/index.php?topic=1931.msg25017#msg25017",
        "date": "November 28, 2010, 02:33:29 AM",
        "content": "<div class=\"post\">Another new user on IRC, Linux this time, was downloading at a rate of 1 block every 4 seconds -- estimated total download time around 4 days.<br/><br/>Other commenters in this thread are correct that upgrading users don't need a block database...\u00a0 but <i>something</i> needs to be done to improve the initial block download experience for new users.\u00a0 Improve the database all you want.. you'll still have peers giving you blocks slowly for any number of reasons.<br/><br/>We have the hashes for genesis block through block 74000 hardcoded (compiled) into bitcoin, so there's no reason why we shouldn't be able to automatically download a compressed zipfile of the block database from <i>anywhere</i>, unpack it, verify it, and start running.<br/></div>",
        "post_num": 13,
        "is_displayed": true,
        "nested_level": 0
    },
    {
        "thread_id": 248,
        "name": "tyler",
        "poster_url": "https://bitcointalk.org/index.php?action=profile;u=2145",
        "subject": "Re: RFC: ship block chain 1-74000 with release tarballs?",
        "url": "https://bitcointalk.org/index.php?topic=1931.msg25054#msg25054",
        "date": "November 28, 2010, 07:23:04 AM",
        "content": "<div class=\"post\"><div class=\"quoteheader\"><a href=\"https://bitcointalk.org/index.php?topic=1931.msg25017#msg25017\">Quote from: jgarzik on November 28, 2010, 02:33:29 AM</a></div><div class=\"quote\">Other commenters in this thread are correct that upgrading users don't need a block database...\u00a0 but <i>something</i> needs to be done to improve the initial block download experience for new users.\u00a0 Improve the database all you want.. you'll still have peers giving you blocks slowly for any number of reasons.<br/><br/><br/></div><br/>*something* needs to be done, the block chain will be *huge* in the next year or so, correct?</div>",
        "post_num": 14,
        "is_displayed": true,
        "nested_level": 0
    },
    {
        "thread_id": 248,
        "name": "jgarzik",
        "poster_url": "https://bitcointalk.org/index.php?action=profile;u=541",
        "subject": "Re: RFC: ship block chain 1-74000 with release tarballs?",
        "url": "https://bitcointalk.org/index.php?topic=1931.msg25058#msg25058",
        "date": "November 28, 2010, 07:33:55 AM",
        "content": "<div class=\"post\"><div class=\"quoteheader\"><a href=\"https://bitcointalk.org/index.php?topic=1931.msg25054#msg25054\">Quote from: tyler on November 28, 2010, 07:23:04 AM</a></div><div class=\"quote\"><div class=\"quoteheader\"><a href=\"https://bitcointalk.org/index.php?topic=1931.msg25017#msg25017\">Quote from: jgarzik on November 28, 2010, 02:33:29 AM</a></div><div class=\"quote\">Other commenters in this thread are correct that upgrading users don't need a block database...\u00a0 but <i>something</i> needs to be done to improve the initial block download experience for new users.\u00a0 Improve the database all you want.. you'll still have peers giving you blocks slowly for any number of reasons.<br/><br/><br/></div><br/>*something* needs to be done, the block chain will be *huge* in the next year or so, correct?<br/></div><br/>Yes, correct.<br/><br/>Presumably at some point there will be a lightweight client that only downloads block headers, but there will still be hundreds of thousands of those...</div>",
        "post_num": 15,
        "is_displayed": true,
        "nested_level": 0
    },
    {
        "thread_id": 248,
        "name": "zipslack",
        "poster_url": "https://bitcointalk.org/index.php?action=profile;u=2084",
        "subject": "Re: RFC: ship block chain 1-74000 with release tarballs?",
        "url": "https://bitcointalk.org/index.php?topic=1931.msg25064#msg25064",
        "date": "November 28, 2010, 08:53:00 AM",
        "content": "<div class=\"post\"><div class=\"quoteheader\"><a href=\"https://bitcointalk.org/index.php?topic=1931.msg24679#msg24679\">Quote from: RHorning on November 26, 2010, 07:17:25 PM</a></div><div class=\"quote\">This is why I'm suggesting that it ought to be a separate but strongly recommended download for new users instead of something combined in the normal distros.<br/></div><br/>Sorry, I misunderstood you.<br/><br/><div class=\"quoteheader\"><a href=\"https://bitcointalk.org/index.php?topic=1931.msg25017#msg25017\">Quote from: jgarzik on November 28, 2010, 02:33:29 AM</a></div><div class=\"quote\">We have the hashes for genesis block through block 74000 hardcoded (compiled) into bitcoin, so there's no reason why we shouldn't be able to automatically download a compressed zipfile of the block database from <i>anywhere</i>, unpack it, verify it, and start running.<br/></div><br/>I suppose you are referring to the checkpoints? If so, as I understand it, they are only applied while verifying a block which has been downloaded. The contents of blk0001.dat and blkindex.dat are <i>never</i> checked by the client, because the client is designed to check that data <i>before</i> it gets written to those files. As satoshi indicated in this thread,<br/><br/><div class=\"quoteheader\"><a href=\"https://bitcointalk.org/index.php?topic=1931.msg24438#msg24438\">Quote from: satoshi on November 25, 2010, 05:51:39 PM</a></div><div class=\"quote\">Doing your own verifying and indexing is the only way to be sure your index data is secure.\u00a0 If you copy blk0001.dat and blkindex.dat from an untrusted source, there's no way to know if you can trust all the contents in them.<br/></div></div>",
        "post_num": 16,
        "is_displayed": true,
        "nested_level": 0
    },
    {
        "thread_id": 248,
        "name": "jgarzik",
        "poster_url": "https://bitcointalk.org/index.php?action=profile;u=541",
        "subject": "Re: RFC: ship block chain 1-74000 with release tarballs?",
        "url": "https://bitcointalk.org/index.php?topic=1931.msg25073#msg25073",
        "date": "November 28, 2010, 10:02:22 AM",
        "content": "<div class=\"post\"><div class=\"quoteheader\"><a href=\"https://bitcointalk.org/index.php?topic=1931.msg25064#msg25064\">Quote from: zipslack on November 28, 2010, 08:53:00 AM</a></div><div class=\"quote\">I suppose you are referring to the checkpoints? If so, as I understand it, they are only applied while verifying a block which has been downloaded. The contents of blk0001.dat and blkindex.dat are <i>never</i> checked by the client, because the client is designed to check that data <i>before</i> it gets written to those files.<br/></div><br/>Not quite true. \u00a0\"-checkblocks\" (CheckBlock()) performs quite a few checks on the contents of blk0001.dat / blkindex.dat. \u00a0AcceptBlock() does a bit more, adding context, but not much more. \u00a0But let's ignore that for the moment.<br/><br/>I think a more important point you're missing is that <b>nobody is proposing that verification be skipped</b>. \u00a0The bitcoin code is quite capable of verifying and indexing untrusted blk0001.dat data. \u00a0It would just need a few modifications to behave sensibly if blkindex.dat is missing.<br/><br/>The proposal is simply:\u00a0 don't download massive amounts of uncompressed data using a protocol (bitcoin P2P) that wasn't designed for bulk data transfer.<br/><br/><div class=\"quoteheader\">Quote</div><div class=\"quote\">As satoshi indicated in this thread,<br/><br/><div class=\"quoteheader\"><a href=\"https://bitcointalk.org/index.php?topic=1931.msg24438#msg24438\">Quote from: satoshi on November 25, 2010, 05:51:39 PM</a></div><div class=\"quote\">Doing your own verifying and indexing is the only way to be sure your index data is secure. \u00a0If you copy blk0001.dat and blkindex.dat from an untrusted source, there's no way to know if you can trust all the contents in them.<br/></div></div><br/>The client is clearly capable of verifying the cryptographic integrity of blk0001.dat from an untrusted source, because it does that for blocks coming in over the network, and blk0001.dat contains... serialized blocks originally received from untrusted sources over the network.<br/><br/>It does not seem overly difficult to pass in blk0001.dat file position data to ProcessBlock(), and simply skip the WriteToDisk() storage call in downstream callee AcceptBlock().<br/><br/></div>",
        "post_num": 17,
        "is_displayed": true,
        "nested_level": 0
    },
    {
        "thread_id": 248,
        "name": "RHorning",
        "poster_url": "https://bitcointalk.org/index.php?action=profile;u=344",
        "subject": "Re: RFC: ship block chain 1-74000 with release tarballs?",
        "url": "https://bitcointalk.org/index.php?topic=1931.msg25122#msg25122",
        "date": "November 28, 2010, 04:09:46 PM",
        "content": "<div class=\"post\"><div class=\"quoteheader\"><a href=\"https://bitcointalk.org/index.php?topic=1931.msg25073#msg25073\">Quote from: jgarzik on November 28, 2010, 10:02:22 AM</a></div><div class=\"quote\">The client is clearly capable of verifying the cryptographic integrity of blk0001.dat from an untrusted source, because it does that for blocks coming in over the network, and blk0001.dat contains... serialized blocks originally received from untrusted sources over the network.<br/><br/>It does not seem overly difficult to pass in blk0001.dat file position data to ProcessBlock(), and simply skip the WriteToDisk() storage call in downstream callee AcceptBlock()<br/></div><br/>Unless I'm mistaken here, what this implies is that at the moment the \"official\" client presumes that blk0001.dat contains validated data, so if you download that data from another source which may have been compromised, at the moment there is no way to verify this information.\u00a0 This is but a temporary danger to be aware of while the software attempts to cope with this particular issue.<br/><br/>On the other hand, somebody could also put into the UI or as a command-line switch on bitcoind some sort of \"reverifications\" of the block data which would be performed locally.\u00a0 I think there are other applications for this including perhaps as a precaution against some virus on your computer manipulating data in the block chain where this would be useful anyway, but it seems like an option which ought to be added to the software.\u00a0 Since the verification code is already in the software, it is merely setting up the algorithm and triggering mechanism to perform that verification.\u00a0 Indeed if there is a particular block which is of concern during the verification process, an effort to \"heal\" the chain based upon block requests to peer nodes could be used to fix potential errors or even discard the whole chain.<br/><br/>I hope such a feature eventually is added.</div>",
        "post_num": 18,
        "is_displayed": true,
        "nested_level": 0
    },
    {
        "thread_id": 248,
        "name": "MoonShadow",
        "poster_url": "https://bitcointalk.org/index.php?action=profile;u=643",
        "subject": "Re: RFC: ship block chain 1-74000 with release tarballs?",
        "url": "https://bitcointalk.org/index.php?topic=1931.msg25126#msg25126",
        "date": "November 28, 2010, 04:25:15 PM",
        "content": "<div class=\"post\">My understanding was that the client already did a blockchain recheck upon startup if the index was missing.\u00a0 I did this when I first started, and it sure seemed like it was marching through the chain.\u00a0 Doesn't it require an index to function anyway?\u00a0 Why would it assume that the blockchain was valid upon startup?\u00a0 Anyone could have edited it.\u00a0 The genesis block is encoded into the client, isn't it?\u00a0 That and the blockchain checkpoints are the only parts that are assumed correct, or am I wrong? There is no good reason to prevent a blockchain download via other methods.\u00a0 In a future with the bitcoin network running close to it's capacity, downloading the entire blockchain over the P2P network will be harmful.\u00a0 <br/><br/>Even a chain that has already been pruned of it's merkle trees should be able to be verified from the start, otherwise what good is using a merkle tree at all?</div>",
        "post_num": 19,
        "is_displayed": true,
        "nested_level": 0
    },
    {
        "thread_id": 248,
        "name": "satoshi",
        "poster_url": "https://bitcointalk.org/index.php?action=profile;u=3",
        "subject": "Re: RFC: ship block chain 1-74000 with release tarballs?",
        "url": "https://bitcointalk.org/index.php?topic=1931.msg25138#msg25138",
        "date": "November 28, 2010, 05:13:01 PM",
        "content": "<div class=\"post\">Despite everything else said, the current next step is:<br/><div class=\"quoteheader\">Quote</div><div class=\"quote\">Someone should experiment with different Berkeley DB settings and see if there's something that makes the download substantially faster. \u00a0If something substantial is discovered, then we can work out the particulars.<br/></div>In particular, I suspect that more read caching might help a lot.<br/><br/><div class=\"quoteheader\"><a href=\"https://bitcointalk.org/index.php?topic=1931.msg25017#msg25017\">Quote from: jgarzik on November 28, 2010, 02:33:29 AM</a></div><div class=\"quote\">Another new user on IRC, Linux this time, was downloading at a rate of 1 block every 4 seconds -- estimated total download time around 4 days.<br/></div>Then something more specific was wrong. \u00a0That's not due to normal initial download time. \u00a0Without more details, it can't be diagnosed. \u00a0If it was due to slow download, did it speed up after 10-20 minutes when the next block broadcast should have made it switch to a faster source? \u00a0debug.log might have clues. \u00a0How fast is their Internet connection? \u00a0Was it steadily slow, or just slow down at one point?<br/><br/><div class=\"quoteheader\">Quote</div><div class=\"quote\">We have the hashes for genesis block through block 74000 hardcoded (compiled) into bitcoin, so there's no reason why we shouldn't be able to automatically download a compressed zipfile of the block database from <i>anywhere</i>, unpack it, verify it, and start running.<br/></div>The 74000 checkpoint is not enough to protect you, and does nothing if the download is already past 74000. \u00a0-checkblocks does more, but is still easily defeated. \u00a0You still must trust the supplier of the zipfile.<br/><br/>If there was a \"verify it\" step, that would take as long as the current normal initial download, in which it is the indexing, not the data download, that is the bottleneck.<br/><br/><div class=\"quoteheader\"><a href=\"https://bitcointalk.org/index.php?topic=1931.msg25058#msg25058\">Quote from: jgarzik on November 28, 2010, 07:33:55 AM</a></div><div class=\"quote\">Presumably at some point there will be a lightweight client that only downloads block headers, but there will still be hundreds of thousands of those...<br/></div>80 bytes per header and no indexing work. \u00a0Might take 1 minute.<br/><br/><div class=\"quoteheader\">Quote</div><div class=\"quote\">uncompressed data using a protocol (bitcoin P2P) that wasn't designed for bulk data transfer.<br/></div>The data is mostly hashes and keys and signatures that are uncompressible.<br/><br/>The speed of initial download is not a reflection of the bulk data transfer rate of the protocol. \u00a0The gating factor is the indexing while it downloads.<br/><br/></div>",
        "post_num": 20,
        "is_displayed": true,
        "nested_level": 0
    },
    {
        "thread_id": 248,
        "name": "jgarzik",
        "poster_url": "https://bitcointalk.org/index.php?action=profile;u=541",
        "subject": "Re: RFC: ship block chain 1-74000 with release tarballs?",
        "url": "https://bitcointalk.org/index.php?topic=1931.msg25164#msg25164",
        "date": "November 28, 2010, 06:59:49 PM",
        "content": "<div class=\"post\"><div class=\"quoteheader\"><a href=\"https://bitcointalk.org/index.php?topic=1931.msg25138#msg25138\">Quote from: satoshi on November 28, 2010, 05:13:01 PM</a></div><div class=\"quote\">If there was a \"verify it\" step, that would take as long as the current initial download, in which it is the indexing, not the data download, that is the bottleneck.<br/>[...]<br/>The speed of initial download is not a reflection of the bulk data transfer rate of the protocol. \u00a0The gating factor is the indexing while it downloads.<br/></div><br/>Sorry, these users' disk and CPU were <i>not</i> at 100%.\u00a0 It is clear the bottleneck is <i>not</i> the database or indexing, for many users.<br/><br/><div class=\"quoteheader\">Quote</div><div class=\"quote\">The data is mostly hashes and keys and signatures that are uncompressible.<br/></div><br/>bzip2 gives you 33% compression ratio, saving many megabytes off a download:<br/><br/><div class=\"codeheader\">Code:</div><div class=\"code\">[jgarzik@bd data]$ tar cvf /tmp/1.tar blk0001.dat <br/>blk0001.dat<br/><br/>[jgarzik@bd data]$ tar cvf /tmp/2.tar blk*.dat<br/>blk0001.dat<br/>blkindex.dat<br/><br/>[jgarzik@bd data]$ bzip2 -9v /tmp/[12].tar<br/>\u00a0 /tmp/1.tar:\u00a0 1.523:1,\u00a0 5.253 bits/byte, 34.34% saved, 55439360 in, 36402074 out.<br/>\u00a0 /tmp/2.tar:\u00a0 1.512:1,\u00a0 5.291 bits/byte, 33.86% saved, 103690240 in, 68577642 out.<br/></div><br/>I wouldn't call 33% \"uncompressible\"</div>",
        "post_num": 21,
        "is_displayed": true,
        "nested_level": 0
    },
    {
        "thread_id": 248,
        "name": "theymos",
        "poster_url": "https://bitcointalk.org/index.php?action=profile;u=35",
        "subject": "Re: RFC: ship block chain 1-74000 with release tarballs?",
        "url": "https://bitcointalk.org/index.php?topic=1931.msg25219#msg25219",
        "date": "November 28, 2010, 10:34:53 PM",
        "content": "<div class=\"post\"><div class=\"quoteheader\"><a href=\"https://bitcointalk.org/index.php?topic=1931.msg25164#msg25164\">Quote from: jgarzik on November 28, 2010, 06:59:49 PM</a></div><div class=\"quote\">Sorry, these users' disk and CPU were <i>not</i> at 100%.\u00a0 It is clear the bottleneck is <i>not</i> the database or indexing, for many users.<br/></div><br/>It seemed to me that it was some sort of disk problem or network condition on his end. Some selected quotes from my IRC log:<br/><div class=\"quoteheader\">Quote</div><div class=\"quote\">&lt;manveru&gt; also, when i woke up, there were thousands of entries in the debug.log that look like: trying connection\u00a0 lastseen=-135.6hrs lasttry=-358582.4hrs<br/>&lt;theymos&gt; How many connections do you have?<br/>&lt;manveru&gt; 2 right now<br/>&lt;theymos&gt; How many blocks do you have?<br/>&lt;manveru&gt; blockcount and blocknumber are 29124<br/>&lt;theymos&gt; How fast is that increasing?<br/>&lt;manveru&gt; around 1 every 4 seconds<br/>&lt;jgarzik&gt; manveru: 32-bit or 64-bit linux?<br/>&lt;manveru&gt; 64<br/>&lt;manveru&gt; now 'blkindex.dat flush' takes a few minutes :|<br/>&lt;manveru&gt; still hangs on flush<br/>&lt;theymos&gt; manveru: Are you on some network file system?<br/>&lt;manveru&gt; no, just a normal harddisk<br/>&lt;manveru&gt; it's only 5200 rpm though</div><br/>Also, replacing the blocks might have prevented him from noticing a transaction:<br/><div class=\"quoteheader\">Quote</div><div class=\"quote\">&lt;manveru&gt; jgarzik: sent me the blocks, but it didn't change my balance<br/>&lt;MT`AwAy&gt; manveru: in your getinfo you're at block 94236 ?<br/>&lt;manveru&gt; yeah</div></div>",
        "post_num": 22,
        "is_displayed": true,
        "nested_level": 0
    },
    {
        "thread_id": 248,
        "name": "jgarzik",
        "poster_url": "https://bitcointalk.org/index.php?action=profile;u=541",
        "subject": "Problem: opening and closing database for each block",
        "url": "https://bitcointalk.org/index.php?topic=1931.msg25434#msg25434",
        "date": "November 29, 2010, 07:01:12 PM",
        "content": "<div class=\"post\"><div class=\"quoteheader\"><a href=\"https://bitcointalk.org/index.php?topic=1931.msg24438#msg24438\">Quote from: satoshi on November 25, 2010, 05:51:39 PM</a></div><div class=\"quote\">Building blkindex.dat is what causes all the disk activity.<br/>[...]<br/>Maybe Berkeley DB has some tweaks we can make to enable or increase cache memory.<br/></div><br/>The following code in AddToBlockIndex(main.cpp) is horribly inefficient, and dramatically slows initial block download:<br/><br/><div class=\"codeheader\">Code:</div><div class=\"code\"> \u00a0 \u00a0CTxDB txdb;<br/>\u00a0\u00a0 \u00a0txdb.WriteBlockIndex(CDiskBlockIndex(pindexNew));<br/><br/>\u00a0\u00a0 \u00a0// New best<br/>\u00a0\u00a0 \u00a0if (pindexNew-&gt;bnChainWork &gt; bnBestChainWork)<br/>\u00a0\u00a0 \u00a0 \u00a0 \u00a0if (!SetBestChain(txdb, pindexNew))<br/>\u00a0\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0return false;<br/><br/>\u00a0\u00a0 \u00a0txdb.Close();<br/></div><br/>This makes it impossible to use a standard technique for loading large amounts of records into a database (db4 or SQL or otherwise): \u00a0wrap multiple record insertions into a single database transaction. \u00a0Ideally, bitcoin would only issue a TxnCommit() for each 1000 blocks or so, during initial block download. \u00a0If a crash occurs, the database remains in a consistent state.<br/><br/>Furthermore, <b>database open + close for each new block</b> is incredibly expensive. \u00a0For each database-open and database-close operation, db4<br/><ul style=\"margin-top: 0; margin-bottom: 0;\"><li>diagnose health of database, to determine if recovery is needed. \u00a0this test may require data copying.</li><li>re-init memory pools</li><li>read database file metadata</li><li>acquire file locks</li><li>read and initialize b-tree or hash-specific metadata. \u00a0build hash table / b-tree roots.</li><li>forces a sync, even if transactions called with DB_TXN_NOSYNC</li><li>fsync memory pool</li></ul><br/>And, additionally, bitcoin forces a database checkpoint, pushing all transactions from log into main database.<br/><br/>That's right, that long list of operations is executed per-database (DB), not per-environment (DB_ENV), for a database close+open cycle. \u00a0To bitcoin, that means we do this for <i>every new block</i>. \u00a0Incredibly inefficient, and not how db4 was designed to be used.<br/><br/>Recommendations:<br/><br/>1) bitcoin should be opening databases, not just environment, at program startup, and closing database at program shutdown. \u00a0db4 is designed to handle crashes, if proper transactional use is maintained -- and bitcoin already uses db4 transactions properly.<br/><br/>2) For the initial block download, txn commit should occur once every N records, not every record. \u00a0I suggest N=1000.<br/><br/><br/><br/>EDIT: \u00a0Updated a couple minor details, and corrected some typos.</div>",
        "post_num": 23,
        "is_displayed": true,
        "nested_level": 0
    },
    {
        "thread_id": 248,
        "name": "satoshi",
        "poster_url": "https://bitcointalk.org/index.php?action=profile;u=3",
        "subject": "Re: RFC: ship block chain 1-74000 with release tarballs?",
        "url": "https://bitcointalk.org/index.php?topic=1931.msg25449#msg25449",
        "date": "November 29, 2010, 08:19:12 PM",
        "content": "<div class=\"post\">It seems like you're inclined to assume everything is wrong more than is actually so.<br/><br/>Writing the block index is light work. \u00a0Building the tx index is much more random access per block. \u00a0I suspect reading all the prev txins is what's slow. \u00a0Read caching would help that. \u00a0It's best if the DB does that. \u00a0Maybe it has a setting for how much cache memory to use.<br/><br/><div class=\"quoteheader\">Quote</div><div class=\"quote\">1) bitcoin should be opening databases, not just environment, at program startup, and closing database at program shutdown. <br/></div>Already does that. \u00a0See CDB. \u00a0The lifetime of the (for instance) CTxDB object is only to support database transactions and to know if anything is still using the database at shutdown.<br/><br/><div class=\"quoteheader\">Quote</div><div class=\"quote\">And, additionally, bitcoin forces a database checkpoint, pushing all transactions from log into main database.<br/></div>If it was doing that it would be much slower. \u00a0It's supposed to be only once a minute or 500 blocks:<br/><br/>\u00a0\u00a0 \u00a0if (strFile == \"blkindex.dat\" &amp;&amp; IsInitialBlockDownload() &amp;&amp; nBestHeight % 500 != 0)<br/>\u00a0\u00a0 \u00a0 \u00a0 \u00a0nMinutes = 1;<br/>\u00a0\u00a0 \u00a0dbenv.txn_checkpoint(0, nMinutes, 0);<br/><br/>Probably should add this:<br/>\u00a0\u00a0 \u00a0if (!fReadOnly)<br/>\u00a0\u00a0 \u00a0 \u00a0 \u00a0dbenv.txn_checkpoint(0, nMinutes, 0);<br/><br/><div class=\"quoteheader\">Quote</div><div class=\"quote\">2) For the initial block download, txn commit should occur once every N records, not every record. \u00a0I suggest N=1000.<br/></div>Does transaction commit imply flush? \u00a0That seems surprising to me. \u00a0I assume a database op wrapped in a transaction would be logged like any other database op. \u00a0Many database applications need to wrap almost every pair of ops in a transaction, such as moving money from one account to another. (debit a, credit b) \u00a0I can't imagine they're required to batch all their stuff up themselves.<br/><br/>In the following cases, would case 1 flush once and case 2 flush twice?<br/><br/>case 1:<br/>write<br/>write<br/>write<br/>write<br/>checkpoint<br/><br/>case 2:<br/>begin transaction<br/>write<br/>write<br/>commit transaction<br/>begin transaction<br/>write<br/>write<br/>commit transaction<br/>checkpoint<br/><br/>Contorting our database usage will not be the right approach. \u00a0It's going to be BDB settings and caching.</div>",
        "post_num": 24,
        "is_displayed": true,
        "nested_level": 0
    },
    {
        "thread_id": 248,
        "name": "jgarzik",
        "poster_url": "https://bitcointalk.org/index.php?action=profile;u=541",
        "subject": "Re: RFC: ship block chain 1-74000 with release tarballs?",
        "url": "https://bitcointalk.org/index.php?topic=1931.msg25467#msg25467",
        "date": "November 29, 2010, 09:00:42 PM",
        "content": "<div class=\"post\">Yeah, I missed the database-open caching buried in all the C++ constructors.\u00a0 Major red herring, sorry about that.<br/><br/>db4 cache control is <a href=\"http://download.oracle.com/docs/cd/E17076_01/html/api_reference/CXX/dbset_cachesize.html\">http://download.oracle.com/docs/cd/E17076_01/html/api_reference/CXX/dbset_cachesize.html</a><br/></div>",
        "post_num": 25,
        "is_displayed": true,
        "nested_level": 0
    },
    {
        "thread_id": 248,
        "name": "jgarzik",
        "poster_url": "https://bitcointalk.org/index.php?action=profile;u=541",
        "subject": "Re: RFC: ship block chain 1-74000 with release tarballs?",
        "url": "https://bitcointalk.org/index.php?topic=1931.msg25531#msg25531",
        "date": "November 30, 2010, 12:06:57 AM",
        "content": "<div class=\"post\">I instrumented my import using the <a href=\"http://bitcointalk.org/index.php?topic=1999.0\">-initblock=FILE patch</a> posted last night, putting printf tracepoints in TxnBegin, TxnCommit, TxnAbort, Read and Write:<br/><br/><div class=\"codeheader\">Code:</div><div class=\"code\">ProcessBlock: ACCEPTED<br/>CDB::Write()<br/>DB4: txn_begin<br/>CDB::Write()<br/>CDB::Write()<br/>CDB::Write()<br/>DB4: txn_commit<br/>SetBestChain: new best=000000005b5c1859db19 \u00a0height=1751 \u00a0work=7524897523416<br/>ProcessBlock: ACCEPTED<br/>CDB::Write()<br/>DB4: txn_begin<br/>CDB::Write()<br/>CDB::Write()<br/>CDB::Write()<br/>DB4: txn_commit<br/>SetBestChain: new best=00000000f396ab6b62ba \u00a0height=1752 \u00a0work=7529192556249<br/>ProcessBlock: ACCEPTED<br/>CDB::Write()<br/>DB4: txn_begin<br/>CDB::Write()<br/>CDB::Write()<br/>CDB::Write()<br/>DB4: txn_commit<br/>SetBestChain: new best=000000000c6bcf972117 \u00a0height=1753 \u00a0work=7533487589082<br/></div><br/>So, it appears that we have a CDB::Write() that occurs outside of a transaction (vTxn is empty??).<br/><br/>txnid==NULL is perfectly legal for db4, but it does mean that callpath may be operating outside of the DB_TXN_NOSYNC flag that is set in ::TxnBegin(). \u00a0Thus, a CDB::Write() outside of a transaction <i>may</i> have synchronous behavior (DB_TXN_SYNC) as governed by DB_AUTO_COMMIT database flag.<br/><br/>EDIT: \u00a0Wrapping WriteBlockIndex() inside a transaction does seem to speed up local disk import (-initblocks).<br/><br/><div class=\"codeheader\">Code:</div><div class=\"code\">--- a/main.cpp<br/>+++ b/main.cpp<br/>@@ -1427,7 +1427,10 @@ bool CBlock::AddToBlockIndex(unsigned int nFile, unsigned<br/>\u00a0 \u00a0 \u00a0pindexNew-&gt;bnChainWork = (pindexNew-&gt;pprev ? pindexNew-&gt;pprev-&gt;bnChainWork <br/>\u00a0<br/>\u00a0 \u00a0 \u00a0CTxDB txdb;<br/>+\u00a0 \u00a0 txdb.TxnBegin();<br/>\u00a0 \u00a0 \u00a0txdb.WriteBlockIndex(CDiskBlockIndex(pindexNew));<br/>+\u00a0 \u00a0 if (!txdb.TxnCommit())<br/>+\u00a0 \u00a0 \u00a0 \u00a0return false;<br/>\u00a0<br/><br/></div><br/>Of course that implies begin+commit+begin+commit in quick succession (SetBestChain), so maybe a less naive approach might be preferred (nested transactions, or wrap both db4 writes in the same transaction).</div>",
        "post_num": 26,
        "is_displayed": true,
        "nested_level": 0
    },
    {
        "thread_id": 248,
        "name": "jgarzik",
        "poster_url": "https://bitcointalk.org/index.php?action=profile;u=541",
        "subject": "Re: RFC: ship block chain 1-74000 with release tarballs?",
        "url": "https://bitcointalk.org/index.php?topic=1931.msg25675#msg25675",
        "date": "November 30, 2010, 07:28:00 AM",
        "content": "<div class=\"post\">I timed two runs with clean data directories (no contents), -noirc, -addnode=10.10.10.1, Linux 64-bit.\u00a0 Hardware: SATA SSD<br/><br/>Mainline, no patches:<br/>\u00a0 \u00a0 \u00a032 minutes to download 94660 blocks.<br/><br/>Mainline + TxnBegin/TxnCommit in AddToBlockIndex():<br/>\u00a0 \u00a0 \u00a025 minutes to download 94660 blocks.<br/><br/></div>",
        "post_num": 27,
        "is_displayed": true,
        "nested_level": 0
    },
    {
        "thread_id": 248,
        "name": "satoshi",
        "poster_url": "https://bitcointalk.org/index.php?action=profile;u=3",
        "subject": "Re: RFC: ship block chain 1-74000 with release tarballs?",
        "url": "https://bitcointalk.org/index.php?topic=1931.msg26016#msg26016",
        "date": "December 01, 2010, 09:25:39 PM",
        "content": "<div class=\"post\">That's a good optimisation.\u00a0 I'll add that next time I update SVN.<br/><br/>More generally, we could also consider this:<br/><br/>\u00a0 \u00a0 \u00a0 \u00a0 dbenv.set_lk_max_objects(10000);<br/>\u00a0 \u00a0 \u00a0 \u00a0 dbenv.set_errfile(fopen(strErrorFile.c_str(), \"a\")); /// debug<br/>\u00a0 \u00a0 \u00a0 \u00a0 dbenv.set_flags(DB_AUTO_COMMIT, 1);<br/>+\u00a0 \u00a0 \u00a0 \u00a0dbenv.set_flags(DB_TXN_NOSYNC, 1);<br/>\u00a0 \u00a0 \u00a0 \u00a0 ret = dbenv.open(strDataDir.c_str(),<br/>\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0DB_CREATE\u00a0 \u00a0 \u00a0|<br/>\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0DB_INIT_LOCK\u00a0 |<br/>\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0DB_INIT_LOG\u00a0 \u00a0|<br/><br/>We would then rely on dbenv.txn_checkpoint(0, 0, 0) in CDB::Close() to flush after wallet writes.<br/></div>",
        "post_num": 28,
        "is_displayed": true,
        "nested_level": 0
    }
]