<!-- extend base layout -->
{% extends "doc.html" %}
{% block doc %}
<style>
  .contents, .references{
    list-style:none;
    text-indent: none;
    padding:0;
    margin:0;
  }
</style>

<div class="col-sm-6 col-sm-offset-3 col-md-6 col-md-offset-3 col-lg-6 col-lg-offset-3">
  <div class="page-header">
    <h1 class="text-center">
      Advances in Distributed Security <br><small>Nick Szabo</small>
    </h1>
    <h4 class="text-center">
      2003<br>
    </h4>
  </div>

  <h2>Table of Contents</h2>

  <ul class="contents">
    <li><a href="#introduction">Introduction</a>
    <li><a href="#fault-tolerance">Fault Tolerance and Security in Networks and Their Services</a>
    <li><a href="#partial-and-total-orders">Partial and Total Orders</a>
    <li><a href="#some-cryptographic-primitives">Some Cryptographic Primitives</a>
    <li><a href="#physical-broadcasts-and-global-clocks">Physical Broadcasts and Global Clocks</a>
    <li><a href="#secure-time-stamping">Secure Time-stamping</a>
    <li><a href="#byzantine-generals-problem">The Byzantine Generals Problem</a>
    <li><a href="#logical-broadcast-over-the-internet">Local Broadcast Over the Internet</a>
    <li><a href="#byzantine-resilient-replications">Byzantine-Resilient Replication</a>
    <li><a href="#some-applications">Some Applications</a>
    <li><a href="#conclusion">Conclusion</a>
    <li><a href="#appendix">Appendix A &ndash; Implementations</a>
    <li><a href="#references">References</a>
  </ul>

  <h3 id="introduction">Introduction</h3>

  <p>
    The last decade has witnessed a revolution in distributed security. Old, pessimistic proofs that security and fault tolerance were "impossible", based on assumptions that protocols had to be deterministic and security and fault tolerance properties had to be absolutely certain, have given way to new proofs and implementations of provable security based on the assumption of cryptography and other randomized protocols that achieving security with very high probability is sufficient. The old view "proved" that the integrity properties of a wide variety of services on which civilization depends, whether <a href="http://szabo.best.vwh.net/synch.html">synchronized clocks</a>, <a href="{{url_for('slugview', slug='secure-property-titles')}}">public directories</a>, <a href="http://oceanstore.cs.berkeley.edu/">censorship-proof file sharing and publication</a>, or <a href="{{url_for('slugview', slug='contracts-with-bearer')}}">issuing money or securities</a> were "impossible" on asynchronous networks like the Internet unless we put unlimited faith in a third party to enforce many of the rules of the service. We now know how to provide such services with a high degree of integrity and availability, yet far more resilient to the possibility that any party might act in a malicious manner. 
  </p>

  <h3 id="fault-tolerance">Fault Tolerance and Security in Networks and Their Services</h3>

  <p>
    As a result of these new possibilities, we are witnessing a shift in the way we view trust. The old view in computer and network security was that trust was all-or-nothing &ndash; either we must place an essentially blind faith in a third party (for example a certificate authority or an issuer of digital cash) or we must protect against a particular mode of attack completely (as, for example, encryption protects against wiretappers). The old view could not handle most real-life situations which don't fall into either of these extremes. Among knowledgeable distributed security designers, unconditionally trusted third parties are now viewed as a cheat &ndash; "here we pray for heavenly benevolence", analogous to the comic-strip mathematician whose proof contains the crucial step, "here a miracle occurs". A third party fully trusted with a security property means that property in fact remains fully insecure &ndash; it means the protocol designer has fobbed off security on somebody else rather than actually solved a security problem.
  </p>

  <p>
    The new view reiterates the desirability of complete protection against attack where it is available, but it adds protection against vast new classes of attacks, and protection of a wide variety of other desirable properties of distributed system, that are impossible to protect without at least some trust assumptions. The new trust assumptions are that participants in a critical public service are partially, usually, or more often than not trustworthy, and often only under certain conditions. The set of parties that make up a critical distributed service is never either completely trustworthy nor all malicious.
  </p>

  <p>
    Modern protocols for critical services such as public directories construct, out of all possible subsets of all participants, <em>attack structures</em> consisting of the worst combination of malicious parties that be tolerated, and their complement, <em>access structures</em>, the minimal set of parties that need to act correctly during this operation to perform the function. (Note that access structures have nothing to do with access control lists, a traditional security method that assumes a fully trusted third party and consists of a static list of persons or classes of persons and the resources or classes of resources they have access to).
  </p>

  <p>
    One particular simple example of such an attack and access structure is a <em>threshold</em> structure where the malicious behavior of up to t out of n participants can be tolerated. Although we will describe the protocols below in terms of threshold structures, it will usually be possible to substitute other partitions of the power set of participants into minimum access and maximum attack structures.
  </p>

  <p>
    A given property of a system has <em>perfect security</em> if its access structure is any participant and its attack structure is the empty set. An example of a property with perfect security is the use of a spinning neutron star called a <em>pulsar</em> as a clock. Its access structure is any party that can receive its natural broadcasts, and its attack structure is the empty set &ndash; given the reasonable presumption that there are no aliens out there who can and want to manipulate the very high energy outputs of pulsars in pursuit of some human ends they have learned about.
  </p>

  <p>
    Another perfect security property is that of encryption against third parties, assuming the encryption is unbreakable. However, if we take into account the receiver of a message as a possible attacker, the broader privacy property is not secure &ndash; the receiver is an attack structure of one who can compromise privacy of the entire message encrypted to him.
  </p>

  <p>
    A security property is <em>almost perfect</em> if its attack structure must contain T-1 out of N participants. For example, in the <em>digital mix</em> of Chaum [C81], for a single message, it would take collusion of N-1 out of N of the mix servers to trace a message. The untraceability property of this system has almost perfect security for a single message. On the other hand, the reliability property of the digital mix is almost perfectly insecure, since any one of the n mix servers can block a message from getting through. Often we must trade off two different properties like this. Since reliability is an error reversible by the end user and a privacy breach is not, the tradeoff made here by Chaum makes sense.
  </p>

  <p>
    Alas, for many desirable properties we cannot achieve either perfect or almost perfect security. For some properties of replicated services &ndash; for some kinds of rules they advertise as following &ndash; we can achieve almost perfect security through, for example, the use of cryptography.
  </p>

  <p>
    For any other properties, the maximum attack structure of malicious and colluding servers that can be tolerated is the set complement of the access structure. For the threshold case, this means that T, the maximum number of malicious and colluding servers that can be tolerated, is a certain fraction of the total number of servers, such as 1/3 or 1/2, of the total number of servers comprising the service, N. That is to say, if T+1 out of N of the servers jointly decide to violate the service's rules and thereby corrupt the system, they can do so. Those who wish to stick to the rules must back out of the corrupted transaction and restart the service out-of-band. For this large class of service properties where the access structure is the set complement of the attack structure, the security of a property is neither perfect or almost perfect at one extreme, nor fully depends on a single trusted party at the other extreme. We say that this class of service properties can be implemented with <em>distributed</em> security.
  </p>

  <p>
    Three of the properties we most often want to protect are privacy, liveness (a.k.a. availability) and integrity. For a replicated service, the main focus of this article, we focus on the security of the integrity and liveness of a single operation of a service. The goal is to create attack structures that are very highly unlikely to fail. If or when such failures of widespread collusion do occur, <em>relying parties</em>, i.e. parties who depend on the properties being secured, must go "out-of-band" and use supplementary systems to repair the system. These supplementary systems might include a wide variety of interparty integrity constraints, audits, blacklisting, and other schemes involving auditing, reputation, and/or cryptography by participants, relying parties, or third parties. These can further motivate servers to preserve the integrity and liveness of these services, and help users to recover after a (now much rarer) successful attack.
  </p>

  <p>
    Since a wide variety of trust assumptions can now be made by a security protocol and this variety can for the first time be described mathematically &ndash; as attack and access structures &ndash; these supplementary systems can focus on keeping the actual attack structures smaller than the maximally tolerated attack structure, rather than on vastly more difficult task of plugging wide-open security holes called "trusted third parties" with these more loosely defined or traditional supplementary institutions.
  </p>

  <h3 id="partial-and-total-orders">Partial and Total Orders</h3>

  <p>
    A basic issue of security and fault tolerance that must be resolved is the secure determination of which order events occured in. If a contract specifies a deadline and it goes down to the wire, how can a relying party or third party adjudicator determine whether the deadline was met? The outcome itself, and its fairness, may rest on fairly deciding who came first. If Alice tries to double-spend a piece of digital cash [C82], only the recipient who checks with the bank first is entitled to its value. But if the bank servers are replicated, which of the two recipients Bob or Charles checked with the bank first? In the case of a <a href="{{url_for('slugview', slug='secure-property-titles')}}">replicated property title service</a> [S98] we have a similar problem &ndash; if Alice transfers her title to two other owners, which new owner actually received the deed? If property is homesteaded on a first-come first-serve basis, which of two or more "land rushers" competing for a lucrative parcel is entitled to the land?
  </p>

  <h4>Lamport (Causal) Order</h4>

  <p>
    Imagine a network where computers don't know how to keep time very well &ndash; they are always getting out of synchronization. (Alas, all you have to really think of here is the actual Internet with PCs). Such a network, called an <em>asynchronous</em> network, lacks an accurate and secure global clock time by which computers can determine the order in which events, which might be messages sent or instructions executed on a particular local machine, have happened. Lamport [L78] was among the first to tackle the problem of how to determine the order of events in such a network.
  </p>

  <p>
    A partial order means that we know in what order some of the elements are, but we aren't sure about some of the others, or some of the others may be equal. An example is the "less than or equal to" relationship among a group of integers, some of which can repeat. Some of the integers we know are less than some others, but an integer paired with itself is equal. A total order, on the other hand, is like the "less than" relationship among unique integers &ndash; we can always tell when one integer is less than another &ndash; there is no ambiguity left. In the case of events, a partial order means for some pairs of events we know whether one occured before another, and for some others we don't know. We use the same symbols as we would use for the analogous case of the integers, so that "x &lt;= y" means "x either occured before y or we don't know whether it occured before or after y". In a total of events, we know for any two events which one happened first. We write "x &lt; y" meaning "x occured before y."
  </p>

  <p>
    Lamport's answer to the event ordering problem was to show that parties (or, we use the terms equivalently here, nodes on the network) can agree on a partial order of events based on causal relationships between these events &ndash; or at least the subset of events where we can determine that causation could occur. On a network, parties influence each other by talking to each other &ndash; in other words, by sending each other messages. Lamport used these messages as the basic building block for constructing his partial order, according to the following rules:
  </p>

  <ol>
    <li>If an event is local to node P, every nonfaulty node agrees on P's opinion of it.</li>
    <li>Every correct node agrees that every message was sent before it was received.</li>
    <li>If we agree that event A occured before event B and that event B occured before event C, then we agree that event A occured before event C. In other words, this partial order is transitive.</li>
  </ol>

  <h4>Breaking Ties &ndash; Creating a Fair Total Order</h4>

  <p>
    The partial order leaves us with the need to agree on how to break ties &ndash; how to resolve the ambiguities where we can't agree which event took place first &ndash; and thus create a total order of events. We want to do so in a way that is <em>fair</em>, in other words, in a way that cannot be manipulated to the advantage of any particular party.
  </p>

  <p>
    An unfair way to create a total order would be to impose a certain predictable rule for breaking ties. For example, we could decide on a total order for the processes and break ties in the causal order by referring to this total order.
  </p>

  <p>
    However, such a procedure creates a bias that may, depending on the application, favor certain servers over others, and therefore allow those servers to favor certain clients over others.
  </p>

  <p>
    One way to break ties fairly is have the participants toss fair coins &ndash; in other words, generate random numbers in a way that cannot be manipulated and then assign those random numbers to events. There are several ways to toss fair coins over a network and we describe one such way below.
  </p>

  <p>
    Another way to break ties fairly is to have the participants agree to a global clock time that is more accurate than the message delays faced by those who would manipulate timing in favor of some party. This entails using a network with very predictable message lag for the clock synchronization protocol and a less predictable one for the other services. We will describe how to do this below.
  </p>

  <h3 id="some-cryptographic-primitives">Some Cryptographic Primitives</h3>

  <p>
    Certain cryptographic primitives play a crucial role in the recent breakthroughs in distributed security that we will discuss here.
  </p>

  <h4>Oblivious Transfer</h4>

  <p>
    Oblivious transfer is an important building block of multiparty secure computations and related protocols. Rather than describing it here, we recommend <a href="http://www.argreenhouse.com/papers/rafail/book.ps">this</a> good introduction.
  </p>

  <h4>Bit Commitment</h4>

  <p>
    Alice wants to prove that she can predict the stock market. But she doesn't want to actually reveal her choice to Bob or anybody else until she's actually had a chance to trade on her prediction. But after the fact, she could just read the closing price and pretend to Bob that she predicted it. How can Alice prove to Bob that she actually predicted the market? Using bit commitments.
  </p>

  <p>
    Bit commitments are ways to commit to a string of numbers or data, in such a way that if or when one later publishes the data, it cannot be forged &ndash; it must be the same as the data you earlier committed to.
  </p>

  <p>
    Alice can commit to her data using one-way functions &ndash; functions that are much harder to compute one way than another. (One-way functions are the most basic building block of cryptography). A common kind of a one-way function is a cryptographic hash function.
  </p>

  <p>
    To create a bit commitment, Alice first generates two random numbers. Then she computes the bit commitment by hashing the two random numbers and the data to be committed to. Append on of the random numbers to the end of the hash and sends it to Bob. The next day when Bob wants to examine the data, and prove that it matches the data Alice originally committed to, Alice provides the data along with the second random number. Bob can verify that it is astronomically unlikely that Alice was able to commit to one predication and then later tell Bob she predicted something else.
  </p>

  <p>
    This protocol is called "bit commitment" because one can commit to even an individual bit this way. If the data has enough entropy one can commit to that data simply by using a hash function and dispense with the random numbers. We will see below how with secure timestamping other parties can determine when the data was committed to.
  </p>

  <h4>Multiparty Secure Computation</h4>

  <p>
    The ideal protocol would have most trustworthy third party imaginable &ndash; a diety who is on everybody's side. All the parties would send their inputs to God. God would reliably determine the results and return the outputs. God being the ultimate in confessional discretion, no party would learn anything more about the other parties' inputs than they could learn from their own inputs and the output.
  </p>

  <p>
    Network security theorists have recently solved this problem to an astonishing extent. They have developed protocols which create virtual machines between two or more parties. Multiparty secure computation allows any number of parties to share a computation, each learning only what can be inferred from their own inputs and the output of the computation. These virtual machines have the exciting property that each party's input is strongly confidential from the other parties. The program and the output are shared by the parties.
  </p>

  <p>
    For example, we could run a spreadsheet across the Internet on this virtual computer. We would agree on a set of formulas and set up the virtual computer with these formulas. Each participant would have their own input cells, which remain blank on the other participants' computers. The participants share output cell(s). Each input our own private data into our input cells. Alice could only learn only as much about the other participants' input cells as she could infer from her own inputs and the output cells.
  </p>

  <p>
    More information on this exciting breakthrough can be found in the accompanying article <a href="{{url_for('slugview', slug='the-god-protocols')}}">“The God Protocols”</a>. Often, as in the spreadsheet example above, the resulting protocol would be very slow. We will now discuss a special efficient kind of multiparty secure computation &ndash; <em>threshold cryptography</em>.
  </p>

{% endblock %}